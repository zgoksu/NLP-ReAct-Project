# -*- coding: utf-8 -*-
"""ReAct.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11sGt-sU8Rt6lKbEAaiae9w4Qf0oXzT3G
"""

!pip install groq

import re
import math
import json
from collections import Counter
from google.colab import userdata
from groq import Groq

groq_api_key = userdata.get("GROQ_API_KEY")
client = Groq(api_key=groq_api_key)

class SimpleRAG:
    def __init__(self):
        self.vector_store = []

    def get_embedding(self, text):
        words = re.findall(r'\w+', text.lower())
        unigrams = Counter(words)
        bigrams = Counter([f"{words[i]}_{words[i+1]}" for i in range(len(words)-1)])
        unigrams.update(bigrams)
        return unigrams

    def _cosine_similarity(self, v1, v2):
        intersection = set(v1.keys()) & set(v2.keys())
        numerator = sum(v1[x] * v2[x] for x in intersection)
        denom = math.sqrt(sum(v1[x]**2 for x in v1)) * math.sqrt(sum(v2[x]**2 for x in v2))
        return numerator / denom if denom else 0.0

    def ingest(self, text):
        chunks = [c.strip() + "." for c in text.split(".") if c.strip()]
        for c in chunks:
            self.vector_store.append({
                "content": c,
                "vector": self.get_embedding(c)
            })

    def retrieve(self, query, top_k=5):
        q_vec = self.get_embedding(query)
        scored = []
        for item in self.vector_store:
            score = self._cosine_similarity(q_vec, item["vector"])
            scored.append((score, item["content"]))
        scored.sort(reverse=True)

        results = []
        for score, content in scored[:top_k]:
            if score > 0:
                results.append(f"[Score: {score:.3f}] {content}")

        return "\n".join(results) if results else "No relevant information found."

rag_engine = SimpleRAG()

with open('cybersec_dataset.json', 'r', encoding='utf-8') as f:
    cyber_data = json.load(f)

for item in cyber_data['knowledge_base']:
    info_text = f"Technique: {item['name']} (ID: {item['technique_id']}). {item['description']} Platform: {', '.join(item['platforms'])}."
    rag_engine.ingest(info_text)

for cmd in cyber_data['commands']:
    cmd_text = f"Known pattern: {cmd['command']}. Category: {cmd['category']}. Risks: {', '.join(cmd['risk_factors'])}. MITRE: {cmd.get('mitre_id', 'N/A')}."
    rag_engine.ingest(cmd_text)

def command_intel(query: str) -> str:
    print(f"\n [RAG] Querying database..: '{query}'")
    result = rag_engine.retrieve(query, top_k=3)
    return result

def calculate_risk_score(indicators: str) -> str:
    print(f"\n [RISK] Calculating..: {indicators}")
    try:
        data = json.loads(indicators)
        score = 0
        reasons = []
        if data.get("encoded_command"): score += 35; reasons.append("Encoded command (+35)")
        if data.get("hidden_window"): score += 20; reasons.append("Hidden window (+20)")
        if data.get("suspicious_binary"): score += 25; reasons.append(f"Suspicious binary: {data.get('suspicious_binary')} (+25)")
        if data.get("network_activity"): score += 20; reasons.append("Network activity (+20)")

        severity = "LOW" if score < 30 else "MEDIUM" if score < 60 else "HIGH" if score < 85 else "CRITICAL"
        return f"Risk Score: {score}/100 | Severity: {severity}\nFactors: " + ", ".join(reasons)
    except:
        return "Error: Invalid format. Please send the data in JSON format."

known_actions = {"command_intel": command_intel, "calculate_risk_score": calculate_risk_score}

system_prompt = """
You are a Senior Cyber Security Analyst. You must follow a strict reasoning process.

RULES:
1. For every query, you MUST first search the knowledge base using 'command_intel' to understand the technical background.
2. Even if you think you know the command, you MUST verify the MITRE techniques and risk factors from the tool.
3. After receiving technical info, you MUST use 'calculate_risk_score' to provide a formal assessment.
4. Your FINAL ANSWER must summarize the technical findings, the attack narrative, and the mitigation steps.

PROCESS:
Thought: What is this command? What flags are suspicious?
Action: command_intel: [query]
PAUSE
Observation: [results]
Thought: Now I see the risks. Let me calculate the formal score.
Action: calculate_risk_score: [json]
PAUSE
Observation: [score]
Answer: [Comprehensive Summary]
""".strip()

class Agent:
    def __init__(self, system):
        self.messages = [{"role": "system", "content": system}]

    def __call__(self, message):
        self.messages.append({"role": "user", "content": message})
        result = self.execute()
        self.messages.append({"role": "assistant", "content": result})
        return result

    def execute(self):
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=self.messages,
            temperature=0,
            stop=["PAUSE", "Observation:"]
        )
        return response.choices[0].message.content

def query(question, max_turns=5):
    agent = Agent(system_prompt)
    next_prompt = question
    action_re = re.compile(r'^Action:\s*(\w+):\s*(.*)$', re.MULTILINE)

    for i in range(max_turns):
        result = agent(next_prompt)
        print(result)

        actions = [action_re.match(line) for line in result.split("\n") if action_re.match(line)]
        if actions:
            action, action_input = actions[0].groups()
            if action in known_actions:
                observation = known_actions[action](action_input.strip())
                print(f"Observation: {observation}")
                next_prompt = f"Observation: {observation}"
            else:
                break
        else:
            break

query("Analyze this command and give me a risk score: powershell -w hidden -enc JAB3AGMAYwAgAD0AIAA=")
